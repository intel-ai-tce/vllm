error_log /var/log/nginx/error.log debug;
worker_processes auto;

events { worker_connections 1024; }

http {
  log_format lb '$remote_addr - [$time_local] "$request" $status '
                'upstream=$upstream_addr ust=$upstream_status '
                'rt=$request_time urt=$upstream_response_time';
  access_log /var/log/nginx/access.log lb;

  # Two separate upstream pools (even if each has 1 server)
  upstream cpu_pool {
    server vllm-service-cpu:80 max_fails=3 fail_timeout=5s;
    keepalive 32;
  }
  upstream gaudi_pool {
    server vllm-service-gaudi:80 max_fails=3 fail_timeout=5s;
    keepalive 32;
  }

  # Force the split: 20% CPU, 80% Gaudi
  split_clients "${request_id}" $chosen_backend {
    20%  "http://cpu_pool";
    *    "http://gaudi_pool";
  }

  server {
    listen 80;

    location / {
      proxy_http_version 1.1;
      proxy_set_header Connection "";
      proxy_set_header Host              $host;
      proxy_set_header X-Real-IP         $remote_addr;
      proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
      proxy_set_header X-Forwarded-Proto $scheme;

      proxy_pass $chosen_backend;

      add_header X-Upstream        $upstream_addr always;
      add_header X-Upstream-Status $upstream_status always;

      # Disable retries so failures show up as errors (not silently retried to Gaudi)
      proxy_next_upstream off;
    }
  }
}

